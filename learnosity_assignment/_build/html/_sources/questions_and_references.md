# Questions and References

## Questions

Were the teachers experienced in grading with a rubic? Studies show teachers experienced with a rubic have a lot more consistent scores (Jeong, 2015)

How were the given models created?

Is it better to round the scores after the regression layer?

How important is it to give feedback to students for their scores? While these types of models are effective at providing a straight score, 
they do not offer an explanation for the score, making it difficult to understand the reasoning behind it.



## References

Doewes, A., Kurdhi, N. A., & Saxena, A. (2023). Evaluating Quadratic Weighted Kappa as the Standard Performance Metric for Automated Essay Scoring. In M. Feng, T. Käser, & P. Talukdar (Eds.), Proceedings of the 16th International Conference on Educational Data Mining (pp. 103-113). Bengaluru, India: International Educational Data Mining Society. https://doi.org/10.5281/zenodo.8115784

P. Wangkriangkri, C. Viboonlarp, A. T. Rutherford and E. Chuangsuwanich, "A Comparative Study of Pretrained Language Models for Automated Essay Scoring with Adversarial Inputs," 2020 IEEE REGION 10 CONFERENCE (TENCON), Osaka, Japan, 2020, pp. 875-880, doi: 10.1109/TENCON50793.2020.9293930.

Jeong, H. (2015). Rubrics in the classroom: do teachers really follow them? Language Testing in Asia, 5(1), 6. https://doi.org/10.1186/s40468-015-0013-5

Firoozi, T., Bulut, O., Epp, C. D., Naeimabadi, A., & Barbosa, D. (2022). The Effect of Fine-tuned Word Embedding Techniques on the Accuracy of Automated Essay Scoring Systems Using Neural Networks. Journal of Applied Testing Technology, 23, 21–29. Retrieved from http://jattjournal.net/index.php/atp/article/view/172687

Ramesh, D., Sanampudi, S.K. An automated essay scoring systems: a systematic literature review. Artif Intell Rev 55, 2495–2527 (2022). https://doi.org/10.1007/s10462-021-10068-2

Mansour, W., Albatarni, S., Eltanbouly, S., & Elsayed, T. (2024). Can Large Language Models Automatically Score Proficiency of Written Essays? arXiv:2403.06149v1 [cs.CL]. Retrieved from https://arxiv.org/abs/2403.06149

Impey, C., Wenger, M., Garuda, N., Golchin, S., & Stamer, S. (2024). Using Large Language Models for Automated Grading of Student Writing about Science. Preprint. https://doi.org/10.21203/rs.3.rs-3962175/v1

Yang, R., Cao, J., Wen, Z., Wu, Y., & He, X. (2020). Enhancing Automated Essay Scoring Performance via Fine-tuning Pre-trained Language Models with Combination of Regression and Ranking. In T. Cohn, Y. He, & Y. Liu (Eds.), Findings of the Association for Computational Linguistics: EMNLP 2020 (pp. 1560-1569). Association for Computational Linguistics. https://doi.org/10.18653/v1/2020.findings-emnlp.141